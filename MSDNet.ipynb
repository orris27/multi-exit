{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSDNet\n",
    "\n",
    "Multi-Scale Dense Networks for Resource Efficient Image Classification\n",
    "\n",
    "Intermediate early-exit classifiers harm the performance of deep neural networks:\n",
    "+ Early classifiers lack coarse-level features\n",
    "+ Early classifiers interfere with later classifiers\n",
    "    - forcing the early layers to learn high level features does harm to the final classifier\n",
    "    \n",
    "MSDNet adopts the following methods to solve the above problems:\n",
    "+ Allow all the classifiers to use the coarse-level features by maintaining feature representations at multiple scales\n",
    "+ Connect different layers\n",
    "\n",
    "\n",
    "Loss function: weighted cumulative cross-entropy\n",
    "\n",
    "Threshold: Threshold can be dynamically deterimined by logits produced by subnetworks and true labels.\n",
    "\n",
    "### Problems Set up\n",
    "1. Anytime Prediction: we can force the network to output the prediction at any location in time\n",
    "2. Budgeted Batch Classification: We have a fixed computational budget for a set of examples. We can reduce the amount of computation on \"easy\" samples to save up computation for \"hard\" samples.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1530/1*WNj1D3cywkTpWfItsgroiw.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output channels change like this:\n",
    "```\n",
    "l1   l2    l3    l4   ...\n",
    "3 -> 16 -> 22 -> 28\n",
    "     32    44    56\n",
    "     64    88    102\n",
    "```\n",
    "+ The authors select the initial number of channels as 16, and increase it by 6 after each layer. \n",
    "+ Each layer contains several scales, which is initially 3, but will decrease till 1 during the forward pass.\n",
    "+ The number of channels in deeper scale size (e.g. 88) are dertermined by basic number of channels (e.g. 22) and scale size (e.g. 2). Therefore, we have: $88 = 22 * 2^2$\n",
    "+ After the table above is dertermined, we can define the convolution layer (e.g. $16 + 32 \\rightarrow 88$)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
